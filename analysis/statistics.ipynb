{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f66c668c",
   "metadata": {},
   "source": [
    "# All the statistics tests in a single file with a long log..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8632de96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importe dependencies\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "# statistics\n",
    "from scipy.stats import shapiro, kstest\n",
    "from scipy.stats import levene\n",
    "from scipy.stats import f_oneway\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "from scipy.stats import boxcox\n",
    "from scipy.stats import yeojohnson\n",
    "from pingouin import welch_anova as pg_welch_anova\n",
    "from scipy import stats\n",
    "import scikit_posthocs as sp\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "from __future__ import annotations\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Optional, Iterable, Tuple\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import logging\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.anova import anova_lm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa0d547c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dataclass\n",
    "class LoadData:\n",
    "    num_rows: Optional[int]\n",
    "    s_folder: str\n",
    "    algo: str\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self._root = Path(self.s_folder)\n",
    "\n",
    "    # ---------- helpers ----------\n",
    "    def _read_csv_safe(self, path: Path, usecols: Optional[Iterable[str]] = None) -> Optional[pd.DataFrame]:\n",
    "        try:\n",
    "            if not path.exists():\n",
    "                return None\n",
    "            return pd.read_csv(path, nrows=self.num_rows, usecols=usecols)\n",
    "        except Exception as e:\n",
    "            logger.info(f\"[read_csv] Failed '{path}': {e}\")\n",
    "            return None\n",
    "\n",
    "    def _glob_one(self, pattern: str) -> Optional[Path]:\n",
    "        hits = list(self._root.glob(pattern))\n",
    "        return hits[0] if hits else None\n",
    "\n",
    "    def _per_run_csv(self, run_id: str, filename: str) -> Path:\n",
    "        return self._root / run_id / filename\n",
    "\n",
    "    # ---------- general ----------\n",
    "    def load_run_table(self) -> pd.DataFrame:\n",
    "        df = self._read_csv_safe(self._root / \"run_table.csv\")\n",
    "        return df if df is not None else pd.DataFrame()\n",
    "\n",
    "    # transforms\n",
    "    def log_transform(self, df: pd.DataFrame, label: str) -> pd.Series:\n",
    "        # keep zeros; NaNs stay NaN\n",
    "        s = pd.to_numeric(df[label], errors=\"coerce\")\n",
    "        return np.log1p(s)\n",
    "\n",
    "    def boxcox_transform(self, df: pd.DataFrame, label: str) -> Tuple[pd.Series, float]:\n",
    "        s = pd.to_numeric(df[label], errors=\"coerce\").dropna()\n",
    "        # ensure strictly positive\n",
    "        s = s[s > 0]\n",
    "        if s.empty:\n",
    "            raise ValueError(f\"boxcox_transform: '{label}' has no positive values\")\n",
    "        transformed, lam = boxcox(s)\n",
    "        out = pd.Series(index=s.index, data=transformed, name=label)\n",
    "        return out, lam\n",
    "\n",
    "    def filter_df(self, df: pd.DataFrame, label: str, value) -> pd.DataFrame:\n",
    "        return df[df[label] == value]\n",
    "\n",
    "    def group_df_by(self, df: pd.DataFrame, key: str, outliers: bool, column_for_outlier: str = \"avg_energy_pct\"):\n",
    "        g = df.groupby(key, dropna=False)\n",
    "        if not outliers:\n",
    "            return g\n",
    "        # apply outlier removal per group, then return a grouped view again\n",
    "        cleaned = g.apply(self.remove_outliers, column_name=column_for_outlier)\n",
    "        cleaned = cleaned.reset_index(level=0, drop=True)  # flatten index from .apply\n",
    "        return cleaned.groupby(key, dropna=False)\n",
    "\n",
    "    # ---------- nav2 aggregates ----------\n",
    "    def load_nav2_success(self, component: Optional[str], outliers: bool) -> pd.DataFrame:\n",
    "        run_table = self.load_run_table()\n",
    "        if run_table.empty:\n",
    "            return run_table\n",
    "\n",
    "        rows = []\n",
    "        for _, row in run_table.iterrows():\n",
    "            run_id = row[\"__run_id\"]\n",
    "            if row.get(\"__done\") == \"TODO\":\n",
    "                continue\n",
    "            path = self._per_run_csv(run_id, \"nav2_performance.csv\")\n",
    "            nav2 = self._read_csv_safe(path)\n",
    "            if nav2 is None:\n",
    "                success = 0\n",
    "            else:\n",
    "                s = pd.to_numeric(nav2.get(\"success\"), errors=\"coerce\")\n",
    "                success = int(np.nansum(s)) if s is not None else 0\n",
    "            rows.append({\"__run_id\": run_id, \"success\": success})\n",
    "\n",
    "        agg = pd.DataFrame(rows)\n",
    "        return run_table.merge(agg, on=\"__run_id\").dropna(subset=[\"__run_id\"])\n",
    "\n",
    "    def load_nav2_time(self, component: Optional[str], outliers: bool, timeout_fallback: float = 120.0) -> pd.DataFrame:\n",
    "        run_table = self.load_run_table()\n",
    "        if run_table.empty:\n",
    "            return run_table\n",
    "\n",
    "        rows = []\n",
    "        for _, row in run_table.iterrows():\n",
    "            run_id = row[\"__run_id\"]\n",
    "            if row.get(\"__done\") == \"TODO\":\n",
    "                continue\n",
    "            path = self._per_run_csv(run_id, \"nav2_performance.csv\")\n",
    "            nav2 = self._read_csv_safe(path)\n",
    "            if nav2 is None:\n",
    "                nav_time = timeout_fallback\n",
    "            else:\n",
    "                s = pd.to_numeric(nav2.get(\"navigation_time\"), errors=\"coerce\")\n",
    "                nav_time = float(np.nansum(s)) if s is not None else timeout_fallback\n",
    "                if nav_time == 0:\n",
    "                    nav_time = timeout_fallback\n",
    "            rows.append({\"__run_id\": run_id, \"navigation_time\": nav_time})\n",
    "\n",
    "        agg = pd.DataFrame(rows)\n",
    "        return run_table.merge(agg, on=\"__run_id\").dropna(subset=[\"__run_id\"])\n",
    "\n",
    "    def load_nav2_path_length(self, component: Optional[str], outliers: bool) -> pd.DataFrame:\n",
    "        run_table = self.load_run_table()\n",
    "        if run_table.empty:\n",
    "            return run_table\n",
    "\n",
    "        rows = []\n",
    "        for _, row in run_table.iterrows():\n",
    "            run_id = row[\"__run_id\"]\n",
    "            if row.get(\"__done\") == \"TODO\":\n",
    "                continue\n",
    "            path = self._per_run_csv(run_id, \"nav2_performance.csv\")\n",
    "            nav2 = self._read_csv_safe(path)\n",
    "            if nav2 is None:\n",
    "                planned = np.nan\n",
    "            else:\n",
    "                s = pd.to_numeric(nav2.get(\"planned_distance_m\"), errors=\"coerce\")\n",
    "                planned = float(np.nansum(s)) if s is not None else np.nan\n",
    "            rows.append({\"__run_id\": run_id, \"planned_distance_m\": planned})\n",
    "\n",
    "        agg = pd.DataFrame(rows)\n",
    "        return run_table.merge(agg, on=\"__run_id\").dropna(subset=[\"__run_id\"])\n",
    "\n",
    "    def load_nav2_recoveries(self, component: Optional[str], outliers: bool) -> pd.DataFrame:\n",
    "        run_table = self.load_run_table()\n",
    "        if run_table.empty:\n",
    "            return run_table\n",
    "\n",
    "        rows = []\n",
    "        for _, row in run_table.iterrows():\n",
    "            run_id = row[\"__run_id\"]\n",
    "            if row.get(\"__done\") == \"TODO\":\n",
    "                continue\n",
    "            path = self._per_run_csv(run_id, \"nav2_performance.csv\")\n",
    "            nav2 = self._read_csv_safe(path)\n",
    "            if nav2 is None:\n",
    "                rec = 0\n",
    "            else:\n",
    "                s = pd.to_numeric(nav2.get(\"recoveries\"), errors=\"coerce\")\n",
    "                rec = int(np.nansum(s)) if s is not None else 0\n",
    "            rows.append({\"__run_id\": run_id, \"recoveries\": rec})\n",
    "\n",
    "        agg = pd.DataFrame(rows)\n",
    "        return run_table.merge(agg, on=\"__run_id\").dropna(subset=[\"__run_id\"])\n",
    "\n",
    "    # ---------- power/CPU/machine ----------\n",
    "    def load_power(self, component: str, transform: bool, outliers: bool) -> pd.DataFrame:\n",
    "        run_table = self.load_run_table()\n",
    "        if run_table.empty:\n",
    "            return run_table\n",
    "\n",
    "        rows = []\n",
    "        for _, row in run_table.iterrows():\n",
    "            run_id = row[\"__run_id\"]\n",
    "            pattern = str(self._per_run_csv(run_id, f\"pj_{component}_server.csv-*.csv\"))\n",
    "            hits = glob.glob(pattern)\n",
    "            if not hits:\n",
    "                continue\n",
    "            df = self._read_csv_safe(Path(hits[0]))\n",
    "            if df is None or \"CPU Power\" not in df:\n",
    "                continue\n",
    "            df[\"CPU Power\"] = pd.to_numeric(df[\"CPU Power\"], errors=\"coerce\")\n",
    "            df = df[df[\"CPU Power\"] > 0.001]\n",
    "            if df.empty:\n",
    "                continue\n",
    "            if transform:\n",
    "                transformed, _ = self.boxcox_transform(df, \"CPU Power\")\n",
    "                df.loc[transformed.index, \"CPU Power\"] = transformed\n",
    "            avg = float(df[\"CPU Power\"].mean())\n",
    "            rows.append({\"__run_id\": run_id, \"avg_energy_pct\": avg})\n",
    "\n",
    "        agg = pd.DataFrame(rows)\n",
    "        if agg.empty:\n",
    "            return run_table\n",
    "        return run_table.merge(agg, on=\"__run_id\").dropna(subset=[\"__run_id\"])\n",
    "\n",
    "    def load_machine_power(self, transform: bool, outliers: bool) -> pd.DataFrame:\n",
    "        # Keep as \"controller\" file unless you actually have a machine-level file elsewhere.\n",
    "        return self.load_power(component=\"controller\", transform=transform, outliers=outliers)\n",
    "\n",
    "    def load_machine_cpu(self, transform: bool, outliers: bool) -> pd.DataFrame:\n",
    "        run_table = self.load_run_table()\n",
    "        if run_table.empty:\n",
    "            return run_table\n",
    "\n",
    "        rows = []\n",
    "        for _, row in run_table.iterrows():\n",
    "            run_id = row[\"__run_id\"]\n",
    "            path = self._per_run_csv(run_id, \"pj_controller_server.csv\")\n",
    "            df = self._read_csv_safe(path)\n",
    "            if df is None or \"CPU Utilization\" not in df:\n",
    "                continue\n",
    "            df[\"CPU Utilization\"] = pd.to_numeric(df[\"CPU Utilization\"], errors=\"coerce\")\n",
    "            df = df[df[\"CPU Utilization\"] > 0.001]\n",
    "            if df.empty:\n",
    "                continue\n",
    "            if transform:\n",
    "                transformed, _ = self.boxcox_transform(df, \"CPU Utilization\")\n",
    "                df.loc[transformed.index, \"CPU Utilization\"] = transformed\n",
    "            avg = float(df[\"CPU Utilization\"].mean())\n",
    "            rows.append({\"__run_id\": run_id, \"avg_energy_pct\": avg})\n",
    "\n",
    "        agg = pd.DataFrame(rows)\n",
    "        if agg.empty:\n",
    "            return run_table\n",
    "        return run_table.merge(agg, on=\"__run_id\").dropna(subset=[\"__run_id\"])\n",
    "\n",
    "    def load_machine_mem(self, transform: bool, outliers: bool) -> pd.DataFrame:\n",
    "        # If you truly want memory, change the column below (e.g., 'Memory Used (MB)')\n",
    "        run_table = self.load_run_table()\n",
    "        if run_table.empty:\n",
    "            return run_table\n",
    "\n",
    "        rows = []\n",
    "        for _, row in run_table.iterrows():\n",
    "            run_id = row[\"__run_id\"]\n",
    "            path = self._per_run_csv(run_id, \"global.csv\")\n",
    "            df = self._read_csv_safe(path)\n",
    "            if df is None or \"cpu_cycles_est\" not in df:\n",
    "                continue\n",
    "            df[\"cpu_cycles_est\"] = pd.to_numeric(df[\"cpu_cycles_est\"], errors=\"coerce\")\n",
    "            df = df[df[\"cpu_cycles_est\"] > 0.001]\n",
    "            if df.empty:\n",
    "                continue\n",
    "            if transform:\n",
    "                transformed, _ = self.boxcox_transform(df, \"cpu_cycles_est\")\n",
    "                df.loc[transformed.index, \"cpu_cycles_est\"] = transformed\n",
    "            avg = float(df[\"cpu_cycles_est\"].mean())\n",
    "            rows.append({\"__run_id\": run_id, \"avg_energy_pct\": avg})\n",
    "\n",
    "        agg = pd.DataFrame(rows)\n",
    "        if agg.empty:\n",
    "            return run_table\n",
    "        return run_table.merge(agg, on=\"__run_id\").dropna(subset=[\"__run_id\"])\n",
    "\n",
    "    # ---------- outliers ----------\n",
    "    def remove_outliers(self, group: pd.DataFrame, column_name: str) -> pd.DataFrame:\n",
    "        s = pd.to_numeric(group[column_name], errors=\"coerce\")\n",
    "        q1 = s.quantile(0.25)\n",
    "        q3 = s.quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        lo = q1 - 1.5 * iqr\n",
    "        hi = q3 + 1.5 * iqr\n",
    "        return group[(s >= lo) & (s <= hi)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbce601e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-08 17:37:04,424 - INFO - Running statistical tests...\n",
      "2025-09-08 17:37:04,993 - INFO - \n",
      "=== small_map | controller | effect of configuration ===\n",
      "2025-09-08 17:37:04,995 - INFO - [Shapiro] 0: W=0.778, p=2.472e-06 → non-normal\n",
      "2025-09-08 17:37:04,996 - INFO - [Shapiro] 1: W=0.727, p=2.733e-07 → non-normal\n",
      "2025-09-08 17:37:04,996 - INFO - [Shapiro] 2: W=0.690, p=6.816e-08 → non-normal\n",
      "2025-09-08 17:37:04,997 - INFO - [Shapiro] 3: W=0.708, p=1.332e-07 → non-normal\n",
      "2025-09-08 17:37:04,997 - INFO - [Shapiro] 4: W=0.800, p=6.732e-06 → non-normal\n",
      "2025-09-08 17:37:04,997 - INFO - [Shapiro] 5: W=0.941, p=0.03731 → non-normal\n",
      "2025-09-08 17:37:04,998 - INFO - [Shapiro] 6: W=0.978, p=0.6029 → normal\n",
      "2025-09-08 17:37:04,998 - INFO - [Shapiro] 7: W=0.671, p=3.347e-08 → non-normal\n",
      "2025-09-08 17:37:04,999 - INFO - [Shapiro] 8: W=0.591, p=2.348e-09 → non-normal\n",
      "2025-09-08 17:37:04,999 - INFO - [Shapiro] 9: W=0.680, p=4.599e-08 → non-normal\n",
      "2025-09-08 17:37:04,999 - INFO - [Shapiro] 10: W=0.743, p=5.29e-07 → non-normal\n",
      "2025-09-08 17:37:05,000 - INFO - [Shapiro] 11: W=0.769, p=1.614e-06 → non-normal\n",
      "2025-09-08 17:37:05,000 - INFO - [Shapiro] 12: W=0.827, p=2.627e-05 → non-normal\n",
      "2025-09-08 17:37:05,000 - INFO - [Shapiro] 13: W=0.810, p=1.126e-05 → non-normal\n",
      "2025-09-08 17:37:05,001 - INFO - [Shapiro] 14: W=0.756, p=9.355e-07 → non-normal\n",
      "2025-09-08 17:37:05,001 - INFO - [Shapiro] 15: W=0.729, p=3.069e-07 → non-normal\n",
      "2025-09-08 17:37:05,002 - INFO - [Shapiro] 16: W=0.837, p=4.438e-05 → non-normal\n",
      "2025-09-08 17:37:05,002 - INFO - [Shapiro] 17: W=0.756, p=9.424e-07 → non-normal\n",
      "2025-09-08 17:37:05,002 - INFO - [Shapiro] 18: W=0.883, p=0.0006301 → non-normal\n",
      "2025-09-08 17:37:05,003 - INFO - [Shapiro] 19: W=0.871, p=0.0002999 → non-normal\n",
      "2025-09-08 17:37:05,006 - INFO - [Levene/Brown–Forsythe] W=1.582, p=0.05424 (center=median)\n",
      "2025-09-08 17:37:05,008 - INFO - [Kruskal–Wallis] H=222.469, p=1.102e-36\n",
      "2025-09-08 17:37:05,022 - INFO - [Post-hoc] Dunn (Bonferroni) computed:\n",
      "2025-09-08 17:37:05,026 - INFO -               0         1             2             3             4             5             6             7             8             9         10            11            12        13        14        15            16        17        18        19\n",
      "0   1.000000e+00  1.000000  6.528059e-03  1.000000e+00  1.000000e+00  1.000000e+00  2.267958e-08  3.241169e-04  2.252483e-04  1.178729e-07  1.000000  1.000000e+00  1.000000e+00  0.200084  0.135571  0.055052  7.166864e-05  1.000000  1.000000  1.000000\n",
      "1   1.000000e+00  1.000000  5.444863e-01  1.000000e+00  1.000000e+00  4.439843e-01  2.461864e-05  5.494856e-02  4.139258e-02  9.591310e-05  1.000000  1.000000e+00  1.000000e+00  1.000000  1.000000  1.000000  1.686408e-02  1.000000  1.000000  1.000000\n",
      "2   6.528059e-03  0.544486  1.000000e+00  1.478431e-04  6.249209e-02  3.203124e-07  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  0.173434  3.834843e-02  9.922292e-04  1.000000  1.000000  1.000000  1.000000e+00  1.000000  1.000000  0.518402\n",
      "3   1.000000e+00  1.000000  1.478431e-04  1.000000e+00  1.000000e+00  1.000000e+00  8.623600e-11  4.471740e-06  2.937946e-06  5.471683e-10  1.000000  1.000000e+00  1.000000e+00  0.008771  0.005475  0.001853  7.869789e-07  0.249111  1.000000  1.000000\n",
      "4   1.000000e+00  1.000000  6.249209e-02  1.000000e+00  1.000000e+00  1.000000e+00  7.379363e-07  4.354129e-03  3.144598e-03  3.343694e-06  1.000000  1.000000e+00  1.000000e+00  1.000000  0.875460  0.402337  1.125767e-03  1.000000  1.000000  1.000000\n",
      "5   1.000000e+00  0.443984  3.203124e-07  1.000000e+00  1.000000e+00  1.000000e+00  1.627240e-14  4.910201e-09  2.987207e-09  1.355581e-13  1.000000  1.000000e+00  1.000000e+00  0.000047  0.000026  0.000007  6.322357e-10  0.003271  0.034571  0.466630\n",
      "6   2.267958e-08  0.000025  1.000000e+00  8.623600e-11  7.379363e-07  1.627240e-14  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  0.000004  3.431076e-07  1.370961e-09  0.295482  0.426460  0.924359  1.000000e+00  0.010830  0.000882  0.000023\n",
      "7   3.241169e-04  0.054949  1.000000e+00  4.471740e-06  4.354129e-03  4.910201e-09  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  0.014294  2.474490e-03  3.814027e-05  1.000000  1.000000  1.000000  1.000000e+00  1.000000  0.653073  0.051845\n",
      "8   2.252483e-04  0.041393  1.000000e+00  2.937946e-06  3.144598e-03  2.987207e-09  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  0.010522  1.771589e-03  2.574798e-05  1.000000  1.000000  1.000000  1.000000e+00  1.000000  0.515939  0.039014\n",
      "9   1.178729e-07  0.000096  1.000000e+00  5.471683e-10  3.343694e-06  1.355581e-13  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  0.000016  1.603849e-06  7.899648e-09  0.688445  0.968433  1.000000  1.000000e+00  0.031026  0.002893  0.000089\n",
      "10  1.000000e+00  1.000000  1.734339e-01  1.000000e+00  1.000000e+00  1.000000e+00  3.761326e-06  1.429397e-02  1.052224e-02  1.591778e-05  1.000000  1.000000e+00  1.000000e+00  1.000000  1.000000  0.977180  3.994163e-03  1.000000  1.000000  1.000000\n",
      "11  1.000000e+00  1.000000  3.834843e-02  1.000000e+00  1.000000e+00  1.000000e+00  3.431076e-07  2.474490e-03  1.771589e-03  1.603849e-06  1.000000  1.000000e+00  1.000000e+00  0.830176  0.587246  0.262440  6.174950e-04  1.000000  1.000000  1.000000\n",
      "12  1.000000e+00  1.000000  9.922292e-04  1.000000e+00  1.000000e+00  1.000000e+00  1.370961e-09  3.814027e-05  2.574798e-05  7.899648e-09  1.000000  1.000000e+00  1.000000e+00  0.042754  0.027770  0.010265  7.495371e-06  0.888802  1.000000  1.000000\n",
      "13  2.000841e-01  1.000000  1.000000e+00  8.770814e-03  1.000000e+00  4.717695e-05  2.954821e-01  1.000000e+00  1.000000e+00  6.884449e-01  1.000000  8.301763e-01  4.275384e-02  1.000000  1.000000  1.000000  1.000000e+00  1.000000  1.000000  1.000000\n",
      "14  1.355715e-01  1.000000  1.000000e+00  5.474984e-03  8.754595e-01  2.629663e-05  4.264600e-01  1.000000e+00  1.000000e+00  9.684331e-01  1.000000  5.872462e-01  2.777002e-02  1.000000  1.000000  1.000000  1.000000e+00  1.000000  1.000000  1.000000\n",
      "15  5.505151e-02  1.000000  1.000000e+00  1.852846e-03  4.023368e-01  6.922015e-06  9.243593e-01  1.000000e+00  1.000000e+00  1.000000e+00  0.977180  2.624399e-01  1.026527e-02  1.000000  1.000000  1.000000  1.000000e+00  1.000000  1.000000  1.000000\n",
      "16  7.166864e-05  0.016864  1.000000e+00  7.869789e-07  1.125767e-03  6.322357e-10  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  0.003994  6.174950e-04  7.495371e-06  1.000000  1.000000  1.000000  1.000000e+00  1.000000  0.243299  0.015845\n",
      "17  1.000000e+00  1.000000  1.000000e+00  2.491111e-01  1.000000e+00  3.270703e-03  1.082974e-02  1.000000e+00  1.000000e+00  3.102570e-02  1.000000  1.000000e+00  8.888023e-01  1.000000  1.000000  1.000000  1.000000e+00  1.000000  1.000000  1.000000\n",
      "18  1.000000e+00  1.000000  1.000000e+00  1.000000e+00  1.000000e+00  3.457140e-02  8.820620e-04  6.530731e-01  5.159392e-01  2.893424e-03  1.000000  1.000000e+00  1.000000e+00  1.000000  1.000000  1.000000  2.432988e-01  1.000000  1.000000  1.000000\n",
      "19  1.000000e+00  1.000000  5.184019e-01  1.000000e+00  1.000000e+00  4.666296e-01  2.268139e-05  5.184499e-02  3.901444e-02  8.869372e-05  1.000000  1.000000e+00  1.000000e+00  1.000000  1.000000  1.000000  1.584497e-02  1.000000  1.000000  1.000000\n",
      "2025-09-08 17:37:05,027 - INFO - \n",
      "=== small_map | controller | effect of number_obstacles ===\n",
      "2025-09-08 17:37:05,028 - INFO - [Shapiro] 0: W=0.837, p=7.165e-20 → non-normal\n",
      "2025-09-08 17:37:05,028 - INFO - [Shapiro] 2: W=0.859, p=1.57e-18 → non-normal\n",
      "2025-09-08 17:37:05,029 - INFO - [Levene/Brown–Forsythe] W=0.004, p=0.951 (center=median)\n",
      "2025-09-08 17:37:05,031 - INFO - [Kruskal–Wallis] H=1.479, p=0.224\n",
      "2025-09-08 17:37:05,601 - INFO - \n",
      "=== small_map | planner | effect of configuration ===\n",
      "2025-09-08 17:37:05,602 - INFO - [Shapiro] 0: W=0.956, p=0.1405 → normal\n",
      "2025-09-08 17:37:05,603 - INFO - [Shapiro] 1: W=0.968, p=0.33 → normal\n",
      "2025-09-08 17:37:05,603 - INFO - [Shapiro] 2: W=0.981, p=0.7378 → normal\n",
      "2025-09-08 17:37:05,604 - INFO - [Shapiro] 3: W=0.916, p=0.006387 → non-normal\n",
      "2025-09-08 17:37:05,604 - INFO - [Shapiro] 4: W=0.972, p=0.4559 → normal\n",
      "2025-09-08 17:37:05,604 - INFO - [Shapiro] 5: W=0.985, p=0.8631 → normal\n",
      "2025-09-08 17:37:05,605 - INFO - [Shapiro] 6: W=0.962, p=0.1993 → normal\n",
      "2025-09-08 17:37:05,605 - INFO - [Shapiro] 7: W=0.943, p=0.04415 → non-normal\n",
      "2025-09-08 17:37:05,606 - INFO - [Shapiro] 8: W=0.939, p=0.03122 → non-normal\n",
      "2025-09-08 17:37:05,606 - INFO - [Shapiro] 9: W=0.491, p=1.847e-10 → non-normal\n",
      "2025-09-08 17:37:05,606 - INFO - [Shapiro] 10: W=0.915, p=0.005313 → non-normal\n",
      "2025-09-08 17:37:05,607 - INFO - [Shapiro] 11: W=0.984, p=0.8408 → normal\n",
      "2025-09-08 17:37:05,607 - INFO - [Shapiro] 12: W=0.864, p=0.0002033 → non-normal\n",
      "2025-09-08 17:37:05,608 - INFO - [Shapiro] 13: W=0.949, p=0.07425 → normal\n",
      "2025-09-08 17:37:05,608 - INFO - [Shapiro] 14: W=0.933, p=0.02323 → non-normal\n",
      "2025-09-08 17:37:05,608 - INFO - [Shapiro] 15: W=0.921, p=0.009115 → non-normal\n",
      "2025-09-08 17:37:05,609 - INFO - [Shapiro] 16: W=0.967, p=0.2858 → normal\n",
      "2025-09-08 17:37:05,609 - INFO - [Shapiro] 17: W=0.924, p=0.01059 → non-normal\n",
      "2025-09-08 17:37:05,609 - INFO - [Shapiro] 18: W=0.988, p=0.9458 → normal\n",
      "2025-09-08 17:37:05,610 - INFO - [Shapiro] 19: W=0.964, p=0.2332 → normal\n",
      "2025-09-08 17:37:05,612 - INFO - [Levene/Brown–Forsythe] W=1.417, p=0.1106 (center=median)\n",
      "2025-09-08 17:37:05,615 - INFO - [Kruskal–Wallis] H=237.752, p=9.255e-40\n",
      "2025-09-08 17:37:05,625 - INFO - [Post-hoc] Dunn (Bonferroni) computed:\n",
      "2025-09-08 17:37:05,630 - INFO -               0         1             2             3             4             5             6         7             8             9         10        11            12            13        14        15            16            17        18        19\n",
      "0   1.000000e+00  1.000000  1.811626e-08  1.000000e+00  1.517282e-03  1.000000e+00  1.000000e+00  1.000000  1.000000e+00  3.807405e-05  1.000000  1.000000  3.633276e-05  1.000000e+00  1.000000  1.000000  1.000000e+00  3.832931e-03  1.000000  1.000000\n",
      "1   1.000000e+00  1.000000  2.158463e-03  9.541060e-01  1.000000e+00  5.592516e-01  5.418005e-02  1.000000  2.476893e-03  3.603315e-01  1.000000  1.000000  3.655280e-01  1.000000e+00  1.000000  1.000000  4.862179e-02  1.000000e+00  1.000000  1.000000\n",
      "2   1.811626e-08  0.002158  1.000000e+00  1.185363e-10  1.000000e+00  2.773115e-11  1.630217e-13  0.004760  3.198330e-16  1.000000e+00  0.000003  0.003028  1.000000e+00  7.901374e-07  0.000004  0.000508  1.298041e-13  1.000000e+00  0.024379  0.000016\n",
      "3   1.000000e+00  0.954106  1.185363e-10  1.000000e+00  4.481016e-05  1.000000e+00  1.000000e+00  0.470513  1.000000e+00  6.436179e-07  1.000000  0.755925  5.930356e-07  1.000000e+00  1.000000  1.000000  1.000000e+00  1.245411e-04  0.145181  1.000000\n",
      "4   1.517282e-03  1.000000  1.000000e+00  4.481016e-05  1.000000e+00  1.670766e-05  3.736179e-07  1.000000  3.295085e-09  1.000000e+00  0.060812  1.000000  1.000000e+00  2.156217e-02  0.059433  1.000000  3.149556e-07  1.000000e+00  1.000000  0.166431\n",
      "5   1.000000e+00  0.559252  2.773115e-11  1.000000e+00  1.670766e-05  1.000000e+00  1.000000e+00  0.264073  1.000000e+00  2.025877e-07  1.000000  0.437316  1.844375e-07  1.000000e+00  1.000000  1.000000  1.000000e+00  4.765438e-05  0.076907  1.000000\n",
      "6   1.000000e+00  0.054180  1.630217e-13  1.000000e+00  3.736179e-07  1.000000e+00  1.000000e+00  0.021919  1.000000e+00  2.732631e-09  1.000000  0.040466  2.393775e-09  1.000000e+00  1.000000  0.170007  1.000000e+00  1.144386e-06  0.005259  1.000000\n",
      "7   1.000000e+00  1.000000  4.759614e-03  4.705126e-01  1.000000e+00  2.640732e-01  2.191945e-02  1.000000  8.360764e-04  6.592958e-01  1.000000  1.000000  6.706247e-01  1.000000e+00  1.000000  1.000000  1.953862e-02  1.000000e+00  1.000000  1.000000\n",
      "8   1.000000e+00  0.002477  3.198330e-16  1.000000e+00  3.295085e-09  1.000000e+00  1.000000e+00  0.000836  1.000000e+00  1.358633e-11  0.290425  0.001756  1.132751e-11  8.001994e-01  0.343045  0.009618  1.000000e+00  1.079674e-08  0.000162  0.109050\n",
      "9   3.807405e-05  0.360332  1.000000e+00  6.436179e-07  1.000000e+00  2.025877e-07  2.732631e-09  0.659296  1.358633e-11  1.000000e+00  0.002757  0.461937  1.000000e+00  8.252900e-04  0.002742  0.123067  2.254190e-09  1.000000e+00  1.000000  0.009193\n",
      "10  1.000000e+00  1.000000  3.471548e-06  1.000000e+00  6.081217e-02  1.000000e+00  1.000000e+00  1.000000  2.904248e-01  2.757027e-03  1.000000  1.000000  2.710753e-03  1.000000e+00  1.000000  1.000000  1.000000e+00  1.364001e-01  1.000000  1.000000\n",
      "11  1.000000e+00  1.000000  3.028299e-03  7.559254e-01  1.000000e+00  4.373156e-01  4.046577e-02  1.000000  1.756074e-03  4.619374e-01  1.000000  1.000000  4.691883e-01  1.000000e+00  1.000000  1.000000  3.624296e-02  1.000000e+00  1.000000  1.000000\n",
      "12  3.633276e-05  0.365528  1.000000e+00  5.930356e-07  1.000000e+00  1.844375e-07  2.393775e-09  0.670625  1.132751e-11  1.000000e+00  0.002711  0.469188  1.000000e+00  8.051375e-04  0.002698  0.124115  1.971192e-09  1.000000e+00  1.000000  0.009115\n",
      "13  1.000000e+00  1.000000  7.901374e-07  1.000000e+00  2.156217e-02  1.000000e+00  1.000000e+00  1.000000  8.001994e-01  8.252900e-04  1.000000  1.000000  8.051375e-04  1.000000e+00  1.000000  1.000000  1.000000e+00  5.013769e-02  1.000000  1.000000\n",
      "14  1.000000e+00  1.000000  3.612436e-06  1.000000e+00  5.943307e-02  1.000000e+00  1.000000e+00  1.000000  3.430445e-01  2.741650e-03  1.000000  1.000000  2.697949e-03  1.000000e+00  1.000000  1.000000  1.000000e+00  1.329079e-01  1.000000  1.000000\n",
      "15  1.000000e+00  1.000000  5.081999e-04  1.000000e+00  1.000000e+00  1.000000e+00  1.700074e-01  1.000000  9.617565e-03  1.230667e-01  1.000000  1.000000  1.241149e-01  1.000000e+00  1.000000  1.000000  1.538005e-01  1.000000e+00  1.000000  1.000000\n",
      "16  1.000000e+00  0.048622  1.298041e-13  1.000000e+00  3.149556e-07  1.000000e+00  1.000000e+00  0.019539  1.000000e+00  2.254190e-09  1.000000  0.036243  1.971192e-09  1.000000e+00  1.000000  0.153801  1.000000e+00  9.674146e-07  0.004649  1.000000\n",
      "17  3.832931e-03  1.000000  1.000000e+00  1.245411e-04  1.000000e+00  4.765438e-05  1.144386e-06  1.000000  1.079674e-08  1.000000e+00  0.136400  1.000000  1.000000e+00  5.013769e-02  0.132908  1.000000  9.674146e-07  1.000000e+00  1.000000  0.357610\n",
      "18  1.000000e+00  1.000000  2.437871e-02  1.451812e-01  1.000000e+00  7.690724e-02  5.258512e-03  1.000000  1.620471e-04  1.000000e+00  1.000000  1.000000  1.000000e+00  1.000000e+00  1.000000  1.000000  4.649087e-03  1.000000e+00  1.000000  1.000000\n",
      "19  1.000000e+00  1.000000  1.626167e-05  1.000000e+00  1.664308e-01  1.000000e+00  1.000000e+00  1.000000  1.090500e-01  9.192836e-03  1.000000  1.000000  9.115184e-03  1.000000e+00  1.000000  1.000000  1.000000e+00  3.576098e-01  1.000000  1.000000\n",
      "2025-09-08 17:37:05,630 - INFO - \n",
      "=== small_map | planner | effect of number_obstacles ===\n",
      "2025-09-08 17:37:05,631 - INFO - [Shapiro] 0: W=0.988, p=0.002703 → non-normal\n",
      "2025-09-08 17:37:05,631 - INFO - [Shapiro] 2: W=0.843, p=2.283e-19 → non-normal\n",
      "2025-09-08 17:37:05,633 - INFO - [Levene/Brown–Forsythe] W=0.467, p=0.4948 (center=median)\n",
      "2025-09-08 17:37:05,634 - INFO - [Kruskal–Wallis] H=0.026, p=0.8707\n",
      "2025-09-08 17:37:06,101 - INFO - \n",
      "=== small_map | overall energy | configuration ===\n",
      "2025-09-08 17:37:06,102 - INFO - [Shapiro] 0: W=0.778, p=2.472e-06 → non-normal\n",
      "2025-09-08 17:37:06,102 - INFO - [Shapiro] 1: W=0.727, p=2.733e-07 → non-normal\n",
      "2025-09-08 17:37:06,102 - INFO - [Shapiro] 2: W=0.690, p=6.816e-08 → non-normal\n",
      "2025-09-08 17:37:06,103 - INFO - [Shapiro] 3: W=0.708, p=1.332e-07 → non-normal\n",
      "2025-09-08 17:37:06,103 - INFO - [Shapiro] 4: W=0.800, p=6.732e-06 → non-normal\n",
      "2025-09-08 17:37:06,103 - INFO - [Shapiro] 5: W=0.941, p=0.03731 → non-normal\n",
      "2025-09-08 17:37:06,104 - INFO - [Shapiro] 6: W=0.978, p=0.6029 → normal\n",
      "2025-09-08 17:37:06,104 - INFO - [Shapiro] 7: W=0.671, p=3.347e-08 → non-normal\n",
      "2025-09-08 17:37:06,105 - INFO - [Shapiro] 8: W=0.591, p=2.348e-09 → non-normal\n",
      "2025-09-08 17:37:06,105 - INFO - [Shapiro] 9: W=0.680, p=4.599e-08 → non-normal\n",
      "2025-09-08 17:37:06,105 - INFO - [Shapiro] 10: W=0.743, p=5.29e-07 → non-normal\n",
      "2025-09-08 17:37:06,106 - INFO - [Shapiro] 11: W=0.769, p=1.614e-06 → non-normal\n",
      "2025-09-08 17:37:06,106 - INFO - [Shapiro] 12: W=0.827, p=2.627e-05 → non-normal\n",
      "2025-09-08 17:37:06,106 - INFO - [Shapiro] 13: W=0.810, p=1.126e-05 → non-normal\n",
      "2025-09-08 17:37:06,107 - INFO - [Shapiro] 14: W=0.756, p=9.355e-07 → non-normal\n",
      "2025-09-08 17:37:06,107 - INFO - [Shapiro] 15: W=0.729, p=3.069e-07 → non-normal\n",
      "2025-09-08 17:37:06,107 - INFO - [Shapiro] 16: W=0.837, p=4.438e-05 → non-normal\n",
      "2025-09-08 17:37:06,108 - INFO - [Shapiro] 17: W=0.756, p=9.424e-07 → non-normal\n",
      "2025-09-08 17:37:06,108 - INFO - [Shapiro] 18: W=0.883, p=0.0006301 → non-normal\n",
      "2025-09-08 17:37:06,108 - INFO - [Shapiro] 19: W=0.871, p=0.0002999 → non-normal\n",
      "2025-09-08 17:37:06,110 - INFO - [Levene/Brown–Forsythe] W=1.582, p=0.05424 (center=median)\n",
      "2025-09-08 17:37:06,112 - INFO - [Kruskal–Wallis] H=222.469, p=1.102e-36\n",
      "2025-09-08 17:37:06,122 - INFO - [Post-hoc] Dunn (Bonferroni) computed:\n",
      "2025-09-08 17:37:06,139 - INFO -               0         1             2             3             4             5             6             7             8             9         10            11            12        13        14        15            16        17        18        19\n",
      "0   1.000000e+00  1.000000  6.528059e-03  1.000000e+00  1.000000e+00  1.000000e+00  2.267958e-08  3.241169e-04  2.252483e-04  1.178729e-07  1.000000  1.000000e+00  1.000000e+00  0.200084  0.135571  0.055052  7.166864e-05  1.000000  1.000000  1.000000\n",
      "1   1.000000e+00  1.000000  5.444863e-01  1.000000e+00  1.000000e+00  4.439843e-01  2.461864e-05  5.494856e-02  4.139258e-02  9.591310e-05  1.000000  1.000000e+00  1.000000e+00  1.000000  1.000000  1.000000  1.686408e-02  1.000000  1.000000  1.000000\n",
      "2   6.528059e-03  0.544486  1.000000e+00  1.478431e-04  6.249209e-02  3.203124e-07  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  0.173434  3.834843e-02  9.922292e-04  1.000000  1.000000  1.000000  1.000000e+00  1.000000  1.000000  0.518402\n",
      "3   1.000000e+00  1.000000  1.478431e-04  1.000000e+00  1.000000e+00  1.000000e+00  8.623600e-11  4.471740e-06  2.937946e-06  5.471683e-10  1.000000  1.000000e+00  1.000000e+00  0.008771  0.005475  0.001853  7.869789e-07  0.249111  1.000000  1.000000\n",
      "4   1.000000e+00  1.000000  6.249209e-02  1.000000e+00  1.000000e+00  1.000000e+00  7.379363e-07  4.354129e-03  3.144598e-03  3.343694e-06  1.000000  1.000000e+00  1.000000e+00  1.000000  0.875460  0.402337  1.125767e-03  1.000000  1.000000  1.000000\n",
      "5   1.000000e+00  0.443984  3.203124e-07  1.000000e+00  1.000000e+00  1.000000e+00  1.627240e-14  4.910201e-09  2.987207e-09  1.355581e-13  1.000000  1.000000e+00  1.000000e+00  0.000047  0.000026  0.000007  6.322357e-10  0.003271  0.034571  0.466630\n",
      "6   2.267958e-08  0.000025  1.000000e+00  8.623600e-11  7.379363e-07  1.627240e-14  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  0.000004  3.431076e-07  1.370961e-09  0.295482  0.426460  0.924359  1.000000e+00  0.010830  0.000882  0.000023\n",
      "7   3.241169e-04  0.054949  1.000000e+00  4.471740e-06  4.354129e-03  4.910201e-09  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  0.014294  2.474490e-03  3.814027e-05  1.000000  1.000000  1.000000  1.000000e+00  1.000000  0.653073  0.051845\n",
      "8   2.252483e-04  0.041393  1.000000e+00  2.937946e-06  3.144598e-03  2.987207e-09  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  0.010522  1.771589e-03  2.574798e-05  1.000000  1.000000  1.000000  1.000000e+00  1.000000  0.515939  0.039014\n",
      "9   1.178729e-07  0.000096  1.000000e+00  5.471683e-10  3.343694e-06  1.355581e-13  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  0.000016  1.603849e-06  7.899648e-09  0.688445  0.968433  1.000000  1.000000e+00  0.031026  0.002893  0.000089\n",
      "10  1.000000e+00  1.000000  1.734339e-01  1.000000e+00  1.000000e+00  1.000000e+00  3.761326e-06  1.429397e-02  1.052224e-02  1.591778e-05  1.000000  1.000000e+00  1.000000e+00  1.000000  1.000000  0.977180  3.994163e-03  1.000000  1.000000  1.000000\n",
      "11  1.000000e+00  1.000000  3.834843e-02  1.000000e+00  1.000000e+00  1.000000e+00  3.431076e-07  2.474490e-03  1.771589e-03  1.603849e-06  1.000000  1.000000e+00  1.000000e+00  0.830176  0.587246  0.262440  6.174950e-04  1.000000  1.000000  1.000000\n",
      "12  1.000000e+00  1.000000  9.922292e-04  1.000000e+00  1.000000e+00  1.000000e+00  1.370961e-09  3.814027e-05  2.574798e-05  7.899648e-09  1.000000  1.000000e+00  1.000000e+00  0.042754  0.027770  0.010265  7.495371e-06  0.888802  1.000000  1.000000\n",
      "13  2.000841e-01  1.000000  1.000000e+00  8.770814e-03  1.000000e+00  4.717695e-05  2.954821e-01  1.000000e+00  1.000000e+00  6.884449e-01  1.000000  8.301763e-01  4.275384e-02  1.000000  1.000000  1.000000  1.000000e+00  1.000000  1.000000  1.000000\n",
      "14  1.355715e-01  1.000000  1.000000e+00  5.474984e-03  8.754595e-01  2.629663e-05  4.264600e-01  1.000000e+00  1.000000e+00  9.684331e-01  1.000000  5.872462e-01  2.777002e-02  1.000000  1.000000  1.000000  1.000000e+00  1.000000  1.000000  1.000000\n",
      "15  5.505151e-02  1.000000  1.000000e+00  1.852846e-03  4.023368e-01  6.922015e-06  9.243593e-01  1.000000e+00  1.000000e+00  1.000000e+00  0.977180  2.624399e-01  1.026527e-02  1.000000  1.000000  1.000000  1.000000e+00  1.000000  1.000000  1.000000\n",
      "16  7.166864e-05  0.016864  1.000000e+00  7.869789e-07  1.125767e-03  6.322357e-10  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  0.003994  6.174950e-04  7.495371e-06  1.000000  1.000000  1.000000  1.000000e+00  1.000000  0.243299  0.015845\n",
      "17  1.000000e+00  1.000000  1.000000e+00  2.491111e-01  1.000000e+00  3.270703e-03  1.082974e-02  1.000000e+00  1.000000e+00  3.102570e-02  1.000000  1.000000e+00  8.888023e-01  1.000000  1.000000  1.000000  1.000000e+00  1.000000  1.000000  1.000000\n",
      "18  1.000000e+00  1.000000  1.000000e+00  1.000000e+00  1.000000e+00  3.457140e-02  8.820620e-04  6.530731e-01  5.159392e-01  2.893424e-03  1.000000  1.000000e+00  1.000000e+00  1.000000  1.000000  1.000000  2.432988e-01  1.000000  1.000000  1.000000\n",
      "19  1.000000e+00  1.000000  5.184019e-01  1.000000e+00  1.000000e+00  4.666296e-01  2.268139e-05  5.184499e-02  3.901444e-02  8.869372e-05  1.000000  1.000000e+00  1.000000e+00  1.000000  1.000000  1.000000  1.584497e-02  1.000000  1.000000  1.000000\n",
      "2025-09-08 17:37:06,140 - INFO - \n",
      "=== small_map | overall energy | number_obstacles ===\n",
      "2025-09-08 17:37:06,144 - INFO - [Shapiro] 0: W=0.837, p=7.165e-20 → non-normal\n",
      "2025-09-08 17:37:06,153 - INFO - [Shapiro] 2: W=0.859, p=1.57e-18 → non-normal\n",
      "2025-09-08 17:37:06,155 - INFO - [Levene/Brown–Forsythe] W=0.004, p=0.951 (center=median)\n",
      "2025-09-08 17:37:06,157 - INFO - [Kruskal–Wallis] H=1.479, p=0.224\n",
      "2025-09-08 17:37:06,670 - INFO - \n",
      "=== large_map | controller | effect of configuration ===\n",
      "2025-09-08 17:37:06,671 - INFO - [Shapiro] 0: W=0.930, p=0.06848 → normal\n",
      "2025-09-08 17:37:06,672 - INFO - [Shapiro] 1: W=0.894, p=0.00809 → non-normal\n",
      "2025-09-08 17:37:06,672 - INFO - [Shapiro] 2: W=0.778, p=4.535e-05 → non-normal\n",
      "2025-09-08 17:37:06,672 - INFO - [Shapiro] 3: W=0.966, p=0.4892 → normal\n",
      "2025-09-08 17:37:06,673 - INFO - [Shapiro] 4: W=0.750, p=1.552e-05 → non-normal\n",
      "2025-09-08 17:37:06,673 - INFO - [Shapiro] 5: W=0.821, p=0.0002591 → non-normal\n",
      "2025-09-08 17:37:06,674 - INFO - [Shapiro] 6: W=0.720, p=5.479e-06 → non-normal\n",
      "2025-09-08 17:37:06,674 - INFO - [Shapiro] 7: W=0.765, p=2.757e-05 → non-normal\n",
      "2025-09-08 17:37:06,674 - INFO - [Shapiro] 8: W=0.965, p=0.4463 → normal\n",
      "2025-09-08 17:37:06,675 - INFO - [Shapiro] 9: W=0.837, p=0.0005061 → non-normal\n",
      "2025-09-08 17:37:06,675 - INFO - [Shapiro] 10: W=0.904, p=0.0145 → non-normal\n",
      "2025-09-08 17:37:06,675 - INFO - [Shapiro] 11: W=0.912, p=0.02189 → non-normal\n",
      "2025-09-08 17:37:06,676 - INFO - [Shapiro] 12: W=0.756, p=1.967e-05 → non-normal\n",
      "2025-09-08 17:37:06,676 - INFO - [Shapiro] 13: W=0.978, p=0.7982 → normal\n",
      "2025-09-08 17:37:06,677 - INFO - [Shapiro] 14: W=0.922, p=0.03862 → non-normal\n",
      "2025-09-08 17:37:06,677 - INFO - [Shapiro] 15: W=0.900, p=0.01601 → non-normal\n",
      "2025-09-08 17:37:06,677 - INFO - [Shapiro] 16: W=0.979, p=0.8413 → normal\n",
      "2025-09-08 17:37:06,678 - INFO - [Shapiro] 17: W=0.970, p=0.6288 → normal\n",
      "2025-09-08 17:37:06,678 - INFO - [Shapiro] 18: W=0.935, p=0.1045 → normal\n",
      "2025-09-08 17:37:06,678 - INFO - [Shapiro] 19: W=0.691, p=5.458e-06 → non-normal\n",
      "2025-09-08 17:37:06,680 - INFO - [Levene/Brown–Forsythe] W=1.138, p=0.3081 (center=median)\n",
      "2025-09-08 17:37:06,682 - INFO - [Kruskal–Wallis] H=142.646, p=5.688e-21\n",
      "2025-09-08 17:37:06,692 - INFO - [Post-hoc] Dunn (Bonferroni) computed:\n",
      "2025-09-08 17:37:06,695 - INFO -           0         1         2         3         4         5             6         7             8         9         10            11        12        13        14            15        16            17        18        19\n",
      "0   1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000e+00  1.000000  1.000000e+00  1.000000  1.000000  4.447555e-03  1.000000  1.000000  0.220271  9.505809e-02  1.000000  1.000000e+00  1.000000  1.000000\n",
      "1   1.000000  1.000000  0.159930  0.550677  1.000000  1.000000  1.022817e-02  1.000000  5.804684e-04  0.134355  1.000000  1.000000e+00  1.000000  1.000000  1.000000  1.000000e+00  0.042312  7.009695e-03  1.000000  0.114134\n",
      "2   1.000000  0.159930  1.000000  1.000000  1.000000  1.000000  1.000000e+00  1.000000  1.000000e+00  1.000000  1.000000  1.317384e-05  1.000000  1.000000  0.002029  7.477856e-04  1.000000  1.000000e+00  1.000000  1.000000\n",
      "3   1.000000  0.550677  1.000000  1.000000  1.000000  1.000000  1.000000e+00  1.000000  1.000000e+00  1.000000  1.000000  9.197709e-05  1.000000  1.000000  0.010046  3.864771e-03  1.000000  1.000000e+00  1.000000  1.000000\n",
      "4   1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  2.717545e-01  1.000000  2.564353e-02  1.000000  1.000000  6.998906e-01  1.000000  1.000000  1.000000  1.000000e+00  0.810530  1.889104e-01  1.000000  1.000000\n",
      "5   1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.133288e-01  1.000000  9.245719e-03  1.000000  1.000000  1.000000e+00  1.000000  1.000000  1.000000  1.000000e+00  0.370220  7.826774e-02  1.000000  0.847655\n",
      "6   1.000000  0.010228  1.000000  1.000000  0.271754  0.113329  1.000000e+00  1.000000  1.000000e+00  1.000000  1.000000  2.111748e-07  0.442099  1.000000  0.000064  2.184517e-05  1.000000  1.000000e+00  1.000000  1.000000\n",
      "7   1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000e+00  1.000000  1.000000e+00  1.000000  1.000000  3.967016e-04  1.000000  1.000000  0.032966  1.316535e-02  1.000000  1.000000e+00  1.000000  1.000000\n",
      "8   1.000000  0.000580  1.000000  1.000000  0.025644  0.009246  1.000000e+00  1.000000  1.000000e+00  1.000000  0.654143  3.422776e-09  0.045414  1.000000  0.000002  6.180267e-07  1.000000  1.000000e+00  1.000000  1.000000\n",
      "9   1.000000  0.134355  1.000000  1.000000  1.000000  1.000000  1.000000e+00  1.000000  1.000000e+00  1.000000  1.000000  1.006728e-05  1.000000  1.000000  0.001624  5.951177e-04  1.000000  1.000000e+00  1.000000  1.000000\n",
      "10  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000e+00  1.000000  6.541433e-01  1.000000  1.000000  2.792621e-02  1.000000  1.000000  0.952592  4.379487e-01  1.000000  1.000000e+00  1.000000  1.000000\n",
      "11  0.004448  1.000000  0.000013  0.000092  0.699891  1.000000  2.111748e-07  0.000397  3.422776e-09  0.000010  0.027926  1.000000e+00  0.438391  0.001715  1.000000  1.000000e+00  0.000002  1.549134e-07  0.000414  0.000011\n",
      "12  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  4.420989e-01  1.000000  4.541432e-02  1.000000  1.000000  4.383914e-01  1.000000  1.000000  1.000000  1.000000e+00  1.000000  3.087794e-01  1.000000  1.000000\n",
      "13  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000e+00  1.000000  1.000000e+00  1.000000  1.000000  1.715487e-03  1.000000  1.000000  0.106807  4.450516e-02  1.000000  1.000000e+00  1.000000  1.000000\n",
      "14  0.220271  1.000000  0.002029  0.010046  1.000000  1.000000  6.366628e-05  0.032966  1.893502e-06  0.001624  0.952592  1.000000e+00  1.000000  0.106807  1.000000  1.000000e+00  0.000414  4.436906e-05  0.031664  0.001522\n",
      "15  0.095058  1.000000  0.000748  0.003865  1.000000  1.000000  2.184517e-05  0.013165  6.180267e-07  0.000595  0.437949  1.000000e+00  1.000000  0.044505  1.000000  1.000000e+00  0.000149  1.528520e-05  0.012776  0.000566\n",
      "16  1.000000  0.042312  1.000000  1.000000  0.810530  0.370220  1.000000e+00  1.000000  1.000000e+00  1.000000  1.000000  2.177480e-06  1.000000  1.000000  0.000414  1.487392e-04  1.000000  1.000000e+00  1.000000  1.000000\n",
      "17  1.000000  0.007010  1.000000  1.000000  0.188910  0.078268  1.000000e+00  1.000000  1.000000e+00  1.000000  1.000000  1.549134e-07  0.308779  1.000000  0.000044  1.528520e-05  1.000000  1.000000e+00  1.000000  1.000000\n",
      "18  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000e+00  1.000000  1.000000e+00  1.000000  1.000000  4.135451e-04  1.000000  1.000000  0.031664  1.277620e-02  1.000000  1.000000e+00  1.000000  1.000000\n",
      "19  1.000000  0.114134  1.000000  1.000000  1.000000  0.847655  1.000000e+00  1.000000  1.000000e+00  1.000000  1.000000  1.091915e-05  1.000000  1.000000  0.001522  5.664919e-04  1.000000  1.000000e+00  1.000000  1.000000\n",
      "2025-09-08 17:37:06,695 - INFO - \n",
      "=== large_map | controller | effect of number_obstacles ===\n",
      "2025-09-08 17:37:06,696 - INFO - [Shapiro] 0: W=0.934, p=1.184e-09 → non-normal\n",
      "2025-09-08 17:37:06,696 - INFO - [Shapiro] 2: W=0.870, p=1.731e-14 → non-normal\n",
      "2025-09-08 17:37:06,698 - INFO - [Levene/Brown–Forsythe] W=0.180, p=0.6717 (center=median)\n",
      "2025-09-08 17:37:06,699 - INFO - [Kruskal–Wallis] H=2.663, p=0.1027\n",
      "2025-09-08 17:37:07,157 - INFO - \n",
      "=== large_map | planner | effect of configuration ===\n",
      "2025-09-08 17:37:07,158 - INFO - [Shapiro] 0: W=0.976, p=0.7697 → normal\n",
      "2025-09-08 17:37:07,158 - INFO - [Shapiro] 1: W=0.960, p=0.3662 → normal\n",
      "2025-09-08 17:37:07,158 - INFO - [Shapiro] 2: W=0.894, p=0.008259 → non-normal\n",
      "2025-09-08 17:37:07,159 - INFO - [Shapiro] 3: W=0.962, p=0.3949 → normal\n",
      "2025-09-08 17:37:07,159 - INFO - [Shapiro] 4: W=0.946, p=0.1674 → normal\n",
      "2025-09-08 17:37:07,160 - INFO - [Shapiro] 5: W=0.971, p=0.5964 → normal\n",
      "2025-09-08 17:37:07,160 - INFO - [Shapiro] 6: W=0.880, p=0.0049 → non-normal\n",
      "2025-09-08 17:37:07,160 - INFO - [Shapiro] 7: W=0.934, p=0.07602 → normal\n",
      "2025-09-08 17:37:07,161 - INFO - [Shapiro] 8: W=0.943, p=0.1357 → normal\n",
      "2025-09-08 17:37:07,161 - INFO - [Shapiro] 9: W=0.942, p=0.1222 → normal\n",
      "2025-09-08 17:37:07,162 - INFO - [Shapiro] 10: W=0.926, p=0.05459 → normal\n",
      "2025-09-08 17:37:07,162 - INFO - [Shapiro] 11: W=0.938, p=0.1072 → normal\n",
      "2025-09-08 17:37:07,162 - INFO - [Shapiro] 12: W=0.921, p=0.0365 → non-normal\n",
      "2025-09-08 17:37:07,163 - INFO - [Shapiro] 13: W=0.981, p=0.8629 → normal\n",
      "2025-09-08 17:37:07,163 - INFO - [Shapiro] 14: W=0.949, p=0.1839 → normal\n",
      "2025-09-08 17:37:07,163 - INFO - [Shapiro] 15: W=0.977, p=0.8154 → normal\n",
      "2025-09-08 17:37:07,164 - INFO - [Shapiro] 16: W=0.979, p=0.845 → normal\n",
      "2025-09-08 17:37:07,164 - INFO - [Shapiro] 17: W=0.944, p=0.1639 → normal\n",
      "2025-09-08 17:37:07,165 - INFO - [Shapiro] 18: W=0.973, p=0.694 → normal\n",
      "2025-09-08 17:37:07,165 - INFO - [Shapiro] 19: W=0.970, p=0.6574 → normal\n",
      "2025-09-08 17:37:07,167 - INFO - [Levene/Brown–Forsythe] W=0.974, p=0.4912 (center=median)\n",
      "2025-09-08 17:37:07,169 - INFO - [Kruskal–Wallis] H=96.826, p=2.003e-12\n",
      "2025-09-08 17:37:07,179 - INFO - [Post-hoc] Dunn (Bonferroni) computed:\n",
      "2025-09-08 17:37:07,182 - INFO -          0         1             2         3         4             5         6         7         8         9         10        11        12        13        14        15        16            17        18        19\n",
      "0   1.00000  1.000000  3.969694e-03  1.000000  1.000000  1.000000e+00  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  2.042982e-02  1.000000  1.000000\n",
      "1   1.00000  1.000000  4.272906e-01  1.000000  1.000000  1.533786e-01  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000e+00  1.000000  1.000000\n",
      "2   0.00397  0.427291  1.000000e+00  0.000004  0.022291  1.930276e-08  0.005151  1.000000  0.051921  1.000000  1.000000  0.288883  0.171551  0.781261  0.009017  0.000037  0.013343  1.000000e+00  1.000000  1.000000\n",
      "3   1.00000  1.000000  4.339443e-06  1.000000  1.000000  1.000000e+00  1.000000  0.237540  1.000000  0.428656  0.473231  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  4.266361e-05  0.036190  0.022190\n",
      "4   1.00000  1.000000  2.229085e-02  1.000000  1.000000  1.000000e+00  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  9.637946e-02  1.000000  1.000000\n",
      "5   1.00000  0.153379  1.930276e-08  1.000000  1.000000  1.000000e+00  1.000000  0.007757  0.897889  0.016150  0.018887  0.231309  0.315129  0.061608  1.000000  1.000000  1.000000  2.983500e-07  0.000840  0.000487\n",
      "6   1.00000  1.000000  5.150637e-03  1.000000  1.000000  1.000000e+00  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  2.583397e-02  1.000000  1.000000\n",
      "7   1.00000  1.000000  1.000000e+00  0.237540  1.000000  7.757467e-03  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  0.736008  1.000000  1.000000e+00  1.000000  1.000000\n",
      "8   1.00000  1.000000  5.192148e-02  1.000000  1.000000  8.978893e-01  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  2.082519e-01  1.000000  1.000000\n",
      "9   1.00000  1.000000  1.000000e+00  0.428656  1.000000  1.615048e-02  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000e+00  1.000000  1.000000\n",
      "10  1.00000  1.000000  1.000000e+00  0.473231  1.000000  1.888666e-02  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000e+00  1.000000  1.000000\n",
      "11  1.00000  1.000000  2.888834e-01  1.000000  1.000000  2.313086e-01  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  9.457112e-01  1.000000  1.000000\n",
      "12  1.00000  1.000000  1.715510e-01  1.000000  1.000000  3.151286e-01  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  6.030444e-01  1.000000  1.000000\n",
      "13  1.00000  1.000000  7.812607e-01  1.000000  1.000000  6.160755e-02  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000e+00  1.000000  1.000000\n",
      "14  1.00000  1.000000  9.016512e-03  1.000000  1.000000  1.000000e+00  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  4.344678e-02  1.000000  1.000000\n",
      "15  1.00000  1.000000  3.667381e-05  1.000000  1.000000  1.000000e+00  1.000000  0.736008  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  2.854540e-04  0.132537  0.083915\n",
      "16  1.00000  1.000000  1.334333e-02  1.000000  1.000000  1.000000e+00  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  5.984478e-02  1.000000  1.000000\n",
      "17  0.02043  1.000000  1.000000e+00  0.000043  0.096379  2.983500e-07  0.025834  1.000000  0.208252  1.000000  1.000000  0.945711  0.603044  1.000000  0.043447  0.000285  0.059845  1.000000e+00  1.000000  1.000000\n",
      "18  1.00000  1.000000  1.000000e+00  0.036190  1.000000  8.400253e-04  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  0.132537  1.000000  1.000000e+00  1.000000  1.000000\n",
      "19  1.00000  1.000000  1.000000e+00  0.022190  1.000000  4.866277e-04  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  0.083915  1.000000  1.000000e+00  1.000000  1.000000\n",
      "2025-09-08 17:37:07,182 - INFO - \n",
      "=== large_map | planner | effect of number_obstacles ===\n",
      "2025-09-08 17:37:07,183 - INFO - [Shapiro] 0: W=0.994, p=0.3897 → normal\n",
      "2025-09-08 17:37:07,183 - INFO - [Shapiro] 2: W=0.991, p=0.1002 → normal\n",
      "2025-09-08 17:37:07,184 - INFO - [Levene/Brown–Forsythe] W=0.022, p=0.8828 (center=median)\n",
      "2025-09-08 17:37:07,186 - INFO - [ANOVA] F=5.347, p=0.02113\n",
      "2025-09-08 17:37:07,274 - INFO - [Post-hoc] Tukey HSD:\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'SimpleTable' object has no attribute 'to_string'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 317\u001b[39m\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    316\u001b[39m     logger.info(\u001b[33m'\u001b[39m\u001b[33mRunning statistical tests...\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m317\u001b[39m     \u001b[43mstatistical_tests\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 295\u001b[39m, in \u001b[36mstatistical_tests\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnumber_obstacles\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m df_power.columns:\n\u001b[32m    294\u001b[39m         logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcomp\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | effect of number_obstacles ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m295\u001b[39m         \u001b[43mchoose_and_run_tests\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_power\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnumber_obstacles\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_col\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mavg_energy_pct\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[38;5;66;03m# Overall energy (machine-level)\u001b[39;00m\n\u001b[32m    298\u001b[39m df_machine = loader.load_machine_power(transform=\u001b[38;5;28;01mFalse\u001b[39;00m, outliers=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 154\u001b[39m, in \u001b[36mchoose_and_run_tests\u001b[39m\u001b[34m(df, key, value_col)\u001b[39m\n\u001b[32m    151\u001b[39m \u001b[38;5;66;03m# 3) Branch\u001b[39;00m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m norm[\u001b[33m\"\u001b[39m\u001b[33mall_normal\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m homo[\u001b[33m\"\u001b[39m\u001b[33mp\u001b[39m\u001b[33m\"\u001b[39m] >= \u001b[32m0.05\u001b[39m:\n\u001b[32m    153\u001b[39m     \u001b[38;5;66;03m# Parametric, equal variances\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m     main = \u001b[43mone_way_anova\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_col\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m norm[\u001b[33m\"\u001b[39m\u001b[33mall_normal\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m homo[\u001b[33m\"\u001b[39m\u001b[33mp\u001b[39m\u001b[33m\"\u001b[39m] < \u001b[32m0.05\u001b[39m:\n\u001b[32m    156\u001b[39m     \u001b[38;5;66;03m# Parametric but unequal variances\u001b[39;00m\n\u001b[32m    157\u001b[39m     main = welch_anova(df, key, value_col)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 93\u001b[39m, in \u001b[36mone_way_anova\u001b[39m\u001b[34m(df, key, value_col)\u001b[39m\n\u001b[32m     91\u001b[39m     posthoc = pairwise_tukeyhsd(values, group_labels, alpha=\u001b[32m0.05\u001b[39m).summary()\n\u001b[32m     92\u001b[39m     logger.info(\u001b[33m\"\u001b[39m\u001b[33m[Post-hoc] Tukey HSD:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m     logger.info(\u001b[43mposthoc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_string\u001b[49m())\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mANOVA\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mF\u001b[39m\u001b[33m\"\u001b[39m: f_stat, \u001b[33m\"\u001b[39m\u001b[33mp\u001b[39m\u001b[33m\"\u001b[39m: p, \u001b[33m\"\u001b[39m\u001b[33mposthoc\u001b[39m\u001b[33m\"\u001b[39m: posthoc}\n",
      "\u001b[31mAttributeError\u001b[39m: 'SimpleTable' object has no attribute 'to_string'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy.stats import shapiro\n",
    "from statsmodels.stats.oneway import anova_oneway   # Welch-capable\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "import pingouin as pg                               # for Games-Howell & Dunn\n",
    "import scikit_posthocs as sp\n",
    "\n",
    "def setup_logger(log_file=\"stats_tests.log\"):\n",
    "    logger = logging.getLogger(\"stats\")\n",
    "    logger.setLevel(logging.INFO)\n",
    "\n",
    "    # Avoid duplicate handlers if re-run in notebooks\n",
    "    if not logger.handlers:\n",
    "        fh = logging.FileHandler(log_file, mode=\"w\", encoding=\"utf-8\")\n",
    "        fh.setLevel(logging.INFO)\n",
    "        ch = logging.StreamHandler()\n",
    "        ch.setLevel(logging.INFO)\n",
    "\n",
    "        formatter = logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "        fh.setFormatter(formatter)\n",
    "        ch.setFormatter(formatter)\n",
    "\n",
    "        logger.addHandler(fh)\n",
    "        logger.addHandler(ch)\n",
    "\n",
    "    return logger\n",
    "\n",
    "logger = setup_logger(\"stats_tests.log\")\n",
    "\n",
    "def _ensure_groups(df: pd.DataFrame, key: str, value_col: str):\n",
    "    if key not in df.columns:\n",
    "        raise ValueError(f\"Grouping key '{key}' not in dataframe.\")\n",
    "    if value_col not in df.columns:\n",
    "        raise ValueError(f\"Value column '{value_col}' not in dataframe.\")\n",
    "    grouped = df[[key, value_col]].dropna().groupby(key)\n",
    "    groups = [g[value_col].values for _, g in grouped]\n",
    "    labels = [name for name, _ in grouped]\n",
    "    return grouped, groups, labels\n",
    "\n",
    "def shapiro_wilk(df: pd.DataFrame, column_name: str, key: str, max_per_group: int = 5000):\n",
    "    \"\"\"\n",
    "    Runs Shapiro per group (downsamples if needed). Returns dict with per-group p-values and overall flag.\n",
    "    \"\"\"\n",
    "    grouped = df.groupby(key)\n",
    "    all_normal = True\n",
    "    results = []\n",
    "    for group_name, g in grouped:\n",
    "        x = pd.to_numeric(g[column_name], errors=\"coerce\").dropna().values\n",
    "        if len(x) < 3:\n",
    "            results.append((group_name, np.nan, np.nan, \"insufficient\"))\n",
    "            continue\n",
    "        # Shapiro becomes unstable for very large n; subsample\n",
    "        if len(x) > max_per_group:\n",
    "            rng = np.random.default_rng(42)\n",
    "            x = rng.choice(x, size=max_per_group, replace=False)\n",
    "        stat, p = shapiro(x)\n",
    "        verdict = \"normal\" if p > 0.05 else \"non-normal\"\n",
    "        if p <= 0.05:\n",
    "            all_normal = False\n",
    "        results.append((group_name, stat, p, verdict))\n",
    "        logger.info(f\"[Shapiro] {group_name}: W={stat:.3f}, p={p:.4g} → {verdict}\")\n",
    "    return {\"all_normal\": all_normal, \"per_group\": results}\n",
    "\n",
    "def levene_test(df: pd.DataFrame, key: str, value_col: str, center: str = \"median\"):\n",
    "    \"\"\"\n",
    "    Brown–Forsythe (Levene with center='median') for homogeneity of variances.\n",
    "    \"\"\"\n",
    "    grouped, groups, labels = _ensure_groups(df, key, value_col)\n",
    "    if len(groups) < 2:\n",
    "        raise ValueError(\"Levene requires ≥2 groups.\")\n",
    "    stat, p = stats.levene(*groups, center=center)\n",
    "    logger.info(f\"[Levene/Brown–Forsythe] W={stat:.3f}, p={p:.4g} (center={center})\")\n",
    "    return {\"stat\": stat, \"p\": p}\n",
    "\n",
    "def one_way_anova(df: pd.DataFrame, key: str, value_col: str):\n",
    "    \"\"\"\n",
    "    Classical one-way ANOVA (equal variances). Also returns Tukey HSD post-hoc if significant.\n",
    "    \"\"\"\n",
    "    grouped, groups, labels = _ensure_groups(df, key, value_col)\n",
    "    if len(groups) < 2:\n",
    "        raise ValueError(\"ANOVA requires ≥2 groups.\")\n",
    "    # stats.f_oneway expects arrays\n",
    "    f_stat, p = stats.f_oneway(*groups)\n",
    "    logger.info(f\"[ANOVA] F={f_stat:.3f}, p={p:.4g}\")\n",
    "    posthoc = None\n",
    "    if p < 0.05:\n",
    "        values = np.concatenate(groups)\n",
    "        group_labels = np.concatenate([[lbl]*len(g) for lbl, g in zip(labels, groups)])\n",
    "        posthoc = pairwise_tukeyhsd(values, group_labels, alpha=0.05).summary()\n",
    "        logger.info(\"[Post-hoc] Tukey HSD:\")\n",
    "        logger.info(posthoc.to_string())\n",
    "    return {\"test\": \"ANOVA\", \"F\": f_stat, \"p\": p, \"posthoc\": posthoc}\n",
    "\n",
    "def welch_anova(df: pd.DataFrame, key: str, value_col: str):\n",
    "    \"\"\"\n",
    "    Welch's ANOVA using statsmodels (correct F and dfs).\n",
    "    \"\"\"\n",
    "    # statsmodels takes a long-form DataFrame\n",
    "    sub = df[[key, value_col]].dropna()\n",
    "    res = anova_oneway(sub, dv=value_col, between=key, use_var=\"unequal\", welch_correction=True)\n",
    "    # res has columns: 'stat', 'pvalue', 'df', etc.\n",
    "    f_stat = res.loc[\"overall\", \"stat\"]\n",
    "    p = res.loc[\"overall\", \"pvalue\"]\n",
    "    logger.info(f\"[Welch ANOVA] F={f_stat:.3f}, p={p:.4g}\")\n",
    "    # Games–Howell post-hoc (unequal variances, unequal n)\n",
    "    gh = pg.pairwise_gameshowell(dv=value_col, between=key, data=sub)\n",
    "    logger.info(\"[Post-hoc] Games–Howell:\")\n",
    "    logger.info(gh.to_string())\n",
    "    return {\"test\": \"Welch ANOVA\", \"F\": f_stat, \"p\": p, \"posthoc\": gh}\n",
    "\n",
    "def kruskal_wallis_test(df: pd.DataFrame, key: str, value_col: str):\n",
    "    grouped, groups, labels = _ensure_groups(df, key, value_col)\n",
    "    if len(groups) < 2:\n",
    "        raise ValueError(\"Kruskal–Wallis requires ≥2 groups.\")\n",
    "    stat, p = stats.kruskal(*groups)\n",
    "    logger.info(f\"[Kruskal–Wallis] H={stat:.3f}, p={p:.4g}\")\n",
    "    posthoc = None\n",
    "    if p < 0.05:\n",
    "        sub = df[[key, value_col]].dropna()        \n",
    "        posthoc = sp.posthoc_dunn(sub, val_col=value_col,\n",
    "                          group_col=key, p_adjust=\"bonferroni\")\n",
    "        # posthoc = pg.pairwise_dunn(sub, dv=value_col, between=key, p_adjust=\"bonferroni\")\n",
    "        logger.info(\"[Post-hoc] Dunn (Bonferroni) computed:\")\n",
    "        logger.info(posthoc.to_string())\n",
    "    return {\"test\": \"Kruskal–Wallis\", \"H\": stat, \"p\": p, \"posthoc\": posthoc}\n",
    "\n",
    "def choose_and_run_tests(df: pd.DataFrame, key: str, value_col: str):\n",
    "    \"\"\"\n",
    "    Orchestrates:\n",
    "      1) normality per group (Shapiro)\n",
    "      2) variance homogeneity (Brown–Forsythe)\n",
    "      3) picks test + post-hoc\n",
    "    Returns a dict with everything.\n",
    "    \"\"\"\n",
    "    res = {\"normality\": None, \"homogeneity\": None, \"main\": None}\n",
    "\n",
    "    # 1) Normality\n",
    "    norm = shapiro_wilk(df, value_col, key)\n",
    "    res[\"normality\"] = norm\n",
    "\n",
    "    # 2) Homogeneity\n",
    "    homo = levene_test(df, key, value_col, center=\"median\")\n",
    "    res[\"homogeneity\"] = homo\n",
    "\n",
    "    k = df[key].nunique()\n",
    "    if k < 2:\n",
    "        raise ValueError(\"Need at least 2 groups to compare.\")\n",
    "\n",
    "    # 3) Branch\n",
    "    if norm[\"all_normal\"] and homo[\"p\"] >= 0.05:\n",
    "        # Parametric, equal variances\n",
    "        main = one_way_anova(df, key, value_col)\n",
    "    elif norm[\"all_normal\"] and homo[\"p\"] < 0.05:\n",
    "        # Parametric but unequal variances\n",
    "        main = welch_anova(df, key, value_col)\n",
    "    else:\n",
    "        # Non-parametric\n",
    "        main = kruskal_wallis_test(df, key, value_col)\n",
    "\n",
    "    res[\"main\"] = main\n",
    "    return res\n",
    "\n",
    "def build_power_df_for_runs(experiment_run: List[str], components: List[str], prefix_f: dict, algo: str = \"nav2\"):\n",
    "    \"\"\"\n",
    "    Returns a dataframe with columns:\n",
    "      ['__run_id', 'configuration', 'number_obstacles', 'avg_energy_pct', 'component', 'experiment_run', ...]\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for run in experiment_run:\n",
    "        s_folder = prefix_f[run]\n",
    "        loader = LoadData(num_rows=None, s_folder=s_folder, algo=algo)\n",
    "        for comp in components:\n",
    "            dfp = loader.load_power(component=comp, transform=False, outliers=False)\n",
    "            if dfp is None or dfp.empty:\n",
    "                continue\n",
    "            dfp = dfp.copy()\n",
    "            dfp[\"component\"] = comp\n",
    "            dfp[\"experiment_run\"] = run\n",
    "            rows.append(dfp)\n",
    "    return pd.concat(rows, ignore_index=True) if rows else pd.DataFrame()\n",
    "\n",
    "def build_overall_energy_df_for_runs(experiment_run: List[str], prefix_f: dict, algo: str = \"nav2\"):\n",
    "    rows = []\n",
    "    for run in experiment_run:\n",
    "        s_folder = prefix_f[run]\n",
    "        loader = LoadData(num_rows=None, s_folder=s_folder, algo=algo)\n",
    "        dfe = loader.load_machine_power(transform=False, outliers=False)\n",
    "        if dfe is None or dfe.empty:\n",
    "            continue\n",
    "        dfe = dfe.copy()\n",
    "        dfe[\"experiment_run\"] = run\n",
    "        rows.append(dfe)\n",
    "    return pd.concat(rows, ignore_index=True) if rows else pd.DataFrame()\n",
    "\n",
    "def compare_runs_by_component(experiment_run, components, prefix_f, logger):\n",
    "    all_df = build_power_df_for_runs(experiment_run, components, prefix_f)\n",
    "    if all_df.empty:\n",
    "        logger.warning(\"[compare_runs_by_component] No power data found.\")\n",
    "        return {}\n",
    "\n",
    "    results = {}\n",
    "    for comp in components:\n",
    "        dfc = all_df[all_df[\"component\"] == comp]\n",
    "        if dfc[\"experiment_run\"].nunique() < 2:\n",
    "            logger.info(f\"[compare_runs_by_component] Skipping {comp}: need both runs.\")\n",
    "            continue\n",
    "\n",
    "        logger.info(f\"\\n=== Compare runs (small_map vs large_map) | component={comp} ===\")\n",
    "        res = choose_and_run_tests(dfc, key=\"experiment_run\", value_col=\"avg_energy_pct\")\n",
    "        results[comp] = res\n",
    "    return results\n",
    "\n",
    "def compare_runs_overall_energy(experiment_run, prefix_f, logger):\n",
    "    all_energy = build_overall_energy_df_for_runs(experiment_run, prefix_f)\n",
    "    if all_energy.empty or all_energy[\"experiment_run\"].nunique() < 2:\n",
    "        logger.warning(\"[compare_runs_overall_energy] Need overall energy from both runs.\")\n",
    "        return None\n",
    "\n",
    "    logger.info(\"\\n=== Compare runs (small_map vs large_map) | overall energy ===\")\n",
    "    return choose_and_run_tests(all_energy, key=\"experiment_run\", value_col=\"avg_energy_pct\")\n",
    "\n",
    "def two_way_anova_map_obstacles_power(experiment_run, components, prefix_f, logger):\n",
    "    \"\"\"\n",
    "    For each component, fits: avg_energy_pct ~ C(experiment_run) * C(number_obstacles)\n",
    "    Returns dict of ANOVA tables.\n",
    "    \"\"\"\n",
    "    all_df = build_power_df_for_runs(experiment_run, components, prefix_f)\n",
    "    if all_df.empty:\n",
    "        logger.warning(\"[two_way_anova_map_obstacles_power] No power data.\")\n",
    "        return {}\n",
    "\n",
    "    out = {}\n",
    "    for comp in components:\n",
    "        dfc = all_df[all_df[\"component\"] == comp].dropna(subset=[\"avg_energy_pct\", \"experiment_run\", \"number_obstacles\"])\n",
    "        if dfc.empty or dfc[\"experiment_run\"].nunique() < 2 or dfc[\"number_obstacles\"].nunique() < 2:\n",
    "            logger.info(f\"[two_way_anova] Skipping {comp}: need ≥2 levels for both factors.\")\n",
    "            continue\n",
    "\n",
    "        # OLS with interaction\n",
    "        model = smf.ols(\"avg_energy_pct ~ C(experiment_run) * C(number_obstacles)\", data=dfc).fit()\n",
    "        aov = anova_lm(model, typ=2)  # Type II ANOVA\n",
    "        logger.info(f\"\\n=== Two-way ANOVA (map × obstacles) | component={comp} ===\\n{aov}\")\n",
    "        out[comp] = aov\n",
    "    return out\n",
    "\n",
    "def two_way_anova_map_obstacles_overall(experiment_run, prefix_f, logger):\n",
    "    df = build_overall_energy_df_for_runs(experiment_run, prefix_f)\n",
    "    if df.empty or df[\"experiment_run\"].nunique() < 2 or df[\"number_obstacles\"].nunique() < 2:\n",
    "        logger.info(\"[two_way_anova_overall] Need ≥2 levels for both factors.\")\n",
    "        return None\n",
    "    model = smf.ols(\"avg_energy_pct ~ C(experiment_run) * C(number_obstacles)\", data=df).fit()\n",
    "    aov = anova_lm(model, typ=2)\n",
    "    logger.info(\"\\n=== Two-way ANOVA (map × obstacles) | overall energy ===\\n%s\", aov)\n",
    "    return aov\n",
    "\n",
    "\n",
    "def statistical_tests():\n",
    "    global component\n",
    "    global algo\n",
    "    global d_folder\n",
    "\n",
    "    # Setting Up Environment Variables\n",
    "    experiment_run = [\"small_map\", \"large_map\"]\n",
    "    components = [\"controller\", \"planner\"]\n",
    "    prefix_f = {\"small_map\": \"data/greenros_reconf_world_small_voxel/\",\n",
    "                \"default\": \"data/greenros_reconf_world_large_voxel_default/\",\n",
    "                \"large_map\": \"data/greenros_reconf_world_large_voxel/\"}\n",
    "    number_obstacles = [0, 2]\n",
    "\n",
    "    # for run in experiment_run:\n",
    "    #     logger.info(f'Map: {run}')\n",
    "    #     s_folder = prefix_f[run]\n",
    "    #     loader = LoadData(num_rows=None, s_folder=s_folder, algo=None)\n",
    "    #     df_ctrl = loader.load_power(\"controller\", transform=False, outliers=False)\n",
    "    #     df_plan = loader.load_power(\"planner\", transform=False, outliers=False)\n",
    "    for run in experiment_run:\n",
    "        s_folder = prefix_f[run]\n",
    "        loader = LoadData(num_rows=None, s_folder=s_folder, algo=\"nav2\")\n",
    "\n",
    "        for comp in components:\n",
    "            df_power = loader.load_power(component=comp, transform=False, outliers=False)\n",
    "            if df_power.empty:\n",
    "                logger.info(f\"[skip] no power data for {run} / {comp}\")\n",
    "                continue\n",
    "\n",
    "            # Effect of configuration\n",
    "            logger.info(f\"\\n=== {run} | {comp} | effect of configuration ===\")\n",
    "            choose_and_run_tests(df_power, key=\"configuration\", value_col=\"avg_energy_pct\")\n",
    "\n",
    "            # Effect of obstacles\n",
    "            if \"number_obstacles\" in df_power.columns:\n",
    "                logger.info(f\"\\n=== {run} | {comp} | effect of number_obstacles ===\")\n",
    "                choose_and_run_tests(df_power, key=\"number_obstacles\", value_col=\"avg_energy_pct\")\n",
    "\n",
    "        # Overall energy (machine-level)\n",
    "        df_machine = loader.load_machine_power(transform=False, outliers=False)\n",
    "        if not df_machine.empty:\n",
    "            logger.info(f\"\\n=== {run} | overall energy | configuration ===\")\n",
    "            choose_and_run_tests(df_machine, key=\"configuration\", value_col=\"avg_energy_pct\")\n",
    "            if \"number_obstacles\" in df_machine.columns:\n",
    "                logger.info(f\"\\n=== {run} | overall energy | number_obstacles ===\")\n",
    "                choose_and_run_tests(df_machine, key=\"number_obstacles\", value_col=\"avg_energy_pct\")\n",
    "\n",
    "    logger.info(\"### SMALL vs LARGE comparisons ###\")\n",
    "    _ = compare_runs_by_component(experiment_run, components, prefix_f, logger)\n",
    "    _ = compare_runs_overall_energy(experiment_run, prefix_f, logger)\n",
    "\n",
    "    logger.info(\"### Two-way ANOVA (map × obstacles) ###\")\n",
    "    _ = two_way_anova_map_obstacles_power(experiment_run, components, prefix_f, logger)\n",
    "    _ = two_way_anova_map_obstacles_overall(experiment_run, prefix_f, logger)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logger.info('Running statistical tests...')\n",
    "    statistical_tests()\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
